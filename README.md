# ETL_Pipeline
Developed a Python-based API client to fetch user data and generate code dynamically for data processing tasks.
Configured and managed a Kafka queue to handle the ingestion of real-time data from the Users API, ensuring efficient and reliable data streaming.
Utilized Apache Spark for distributed data processing, implementing various transformations and aggregations to extract valuable insights from the user data.
Implemented a MongoDB database as the storage solution for processed data, enabling fast retrieval and scalability.
Worked on optimizing the pipeline for performance, ensuring low latency and high throughput across the system.
Collaborated with cross-functional teams to integrate the pipeline with other services and to troubleshoot and resolve issues related to data flow and storage
